The dataset used for this project was built to support a customer support query classification task. It consisted of 210 entries, equally distributed across six categories: Technical Issue, Billing, General Inquiry, Account Access, Cancellation Request, and Product Feedback. Each category contained 35 unique samples, ensuring a balanced dataset suitable for training a multi-class classifier. The data was synthetically generated to reflect realistic customer queries based on actual support patterns observed across platforms. All entries were thoroughly cleaned before training. The cleaning process involved standardizing text to lowercase, normalizing contractions, correcting spelling and grammar, and removing punctuation inconsistencies. Entries were also checked for duplication or vague phrasing to maintain clarity and class distinction. Labeling was done manually, with each query clearly aligned to one of the six intent categories. Care was taken to vary linguistic structure, including both questions and statements, to improve the model’s robustness during generalization. The dataset was saved in both CSV and JSONL formats to facilitate compatibility with different training pipelines.

The model chosen for fine-tuning was distilbert-base-uncased, a lightweight yet powerful transformer model from Hugging Face’s Transformers library. This model is well-suited for text classification tasks and offers fast training times with competitive accuracy. The training process began with environment setup, including installing essential libraries like transformers, datasets, torch, and tensorflow. GPU availability was verified to ensure efficient training. The dataset was loaded and tokenized using the AutoTokenizer, with padding and truncation enabled to maintain consistent input lengths. Preprocessing also included mapping the text input to token IDs while keeping attention masks for the model’s encoder. The dataset was then split into training and test sets. Training arguments were defined using Hugging Face’s TrainingArguments, with three training epochs, a learning rate of 2e-5, batch size of 16, and weight decay of 0.01. The Hugging Face Trainer class was used to manage training, evaluation, and logging. Upon completion, the model and tokenizer were saved locally in the ./fine_tuned_model directory, making them ready for deployment or additional evaluation.

The fine-tuned model was evaluated using accuracy, precision, recall, and F1 score. On the test set, the model achieved an overall accuracy of %, with a macro-averaged precision of %, recall of %, and F1 score of %. Strengths of the model included its high accuracy on clearly defined query types such as Account Access and Billing. The balanced dataset and structured labeling contributed significantly to this performance. Additionally, the model demonstrated solid generalization even when presented with varied phrasings and query styles. However, the model occasionally confused overlapping categories—particularly General Inquiry and Product Feedback. This was attributed to subtle linguistic similarities in polite feature requests versus product-related questions. Another limitation was its difficulty handling queries with multiple intents, such as billing and technical issues combined in a single message.

This fine-tuned model could be integrated into a customer support system to automatically classify incoming tickets, reducing the time required for human triage and improving overall efficiency. Once integrated with a customer relationship management (CRM) platform, it could instantly route queries to the correct department, prioritize urgent technical issues, and filter general inquiries for automated replies. The impact of such automation includes reduced wait times for customers, improved staff productivity, and more accurate tracking of customer concerns. A potential improvement for future iterations would be the introduction of multi-label classification. This would allow the model to tag queries with more than one category, better reflecting real-world support tickets. Additionally, expanding the dataset with real customer data and further fine-tuning on edge cases would enhance accuracy and reliability in production.